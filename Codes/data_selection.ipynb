{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f8aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from typing import Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fceac213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vector(event_list, n):\n",
    "    vector = np.zeros(n)\n",
    "    for event in event_list:\n",
    "        index = int(event[1:]) - 1  # Convert 'E1' to 0, 'E2' to 1, etc.\n",
    "        if 0 <= index < n:\n",
    "            vector[index] += 1\n",
    "    return vector\n",
    "\n",
    "\n",
    "def train_test_split_for_data_autoencoder(path: str, test_size: float=0.3):\n",
    "    #Loading in the data\n",
    "    data_df = pd.read_csv(path)\n",
    "    #Converting the labels to binary numbers, 0 for success, 1 for failure\n",
    "    mask = data_df['Final Label'] == 'Success'\n",
    "    data_df.loc[mask, 'label'] = 0\n",
    "    data_df.loc[~mask, 'label'] = 1\n",
    "    #I do not need the index column\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "\n",
    "    #Once converted, the strings of the event IDs are also unnecessary\n",
    "    data_df['Events']  = data_df['New Event ID'].apply(ast.literal_eval)\n",
    "    #Calculating the maximum value of the En type events\n",
    "    max_n = max(int(e[1:]) for sublist in data_df['Events'] for e in sublist)\n",
    "    data_df['Event_Count_Vector'] = data_df['Events'].apply(lambda x: count_vector(x, max_n))\n",
    "    data_df.drop(columns=['Final Label', 'Unnamed: 0', 'New Event ID', 'Events', 'BlockId'], inplace=True)\n",
    "    count_vector_df = pd.DataFrame(data_df['Event_Count_Vector'].tolist(), index=data_df.index)\n",
    "\n",
    "    #For logistic regression\n",
    "    count_vector_df.columns = [f'feature_{i+1}' for i in range(count_vector_df.shape[1])]\n",
    "    #data_df = pd.concat([data_df, count_vector_df], axis=1)\n",
    "    #data_df.drop(columns='Event_Count_Vector', inplace = True)\n",
    "\n",
    "\n",
    "    success_df = data_df.loc[data_df['label'] == 0].copy(deep=True)\n",
    "    fail_df = data_df.loc[data_df['label'] == 1].copy(deep=True)\n",
    "    success_df_label = success_df['label'].copy(deep=True)\n",
    "    success_df.drop(columns='label', inplace=True)\n",
    "    fail_df_label = fail_df['label'].copy(deep=True)\n",
    "    fail_df.drop(columns='label', inplace=True)\n",
    "    x_train_success, x_test_success,y_train_success, y_test_success = train_test_split(success_df, success_df_label, test_size=test_size, shuffle=True, random_state=42)\n",
    "    x_train_fail, x_test_fail, y_train_fail, y_test_fail = train_test_split(fail_df, fail_df_label, test_size=test_size, shuffle = True, random_state=42)\n",
    "    \n",
    "    return x_train_success, x_train_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef10944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arrays_from_sequences(data_df:pd.DataFrame) -> Tuple[np.array, np.array]:\n",
    "    X, y = [], []\n",
    "    for _, row in data_df.iterrows():\n",
    "        seq = row['Event_sequences']\n",
    "        label = row['label']\n",
    "        X.append(seq)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def sequence_for_embedding(event_list, n, length_of_sequence: int=50) -> np.array:\n",
    "    sequence = []\n",
    "    i = 0\n",
    "    for event in event_list:\n",
    "        sequence.append(int(event[1:]) - 1)\n",
    "    if len(sequence) < length_of_sequence:\n",
    "        for i in range(length_of_sequence-len(sequence)):\n",
    "            sequence.append(n)\n",
    "        return np.array(sequence)\n",
    "    else:\n",
    "        return np.array(sequence[0:length_of_sequence])\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aaf64ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/HDFS_v1/Processed_data/processed_labeled_data.csv'\n",
    "x_train_success, x_train_fail = train_test_split_for_data_autoencoder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4effcf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_selection(x_train_success_df: pd.DataFrame, number_to_choose: int):\n",
    "    sampled_df = x_train_success_df.sample(n=int(len(x_train_success_df)*1/(1+number_to_choose)), replace=False, random_state=None).reset_index(drop=True)\n",
    "    return sampled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f84683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Event_Count_Vector'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_success.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa4ae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathb\\AppData\\Local\\Temp\\ipykernel_17580\\902015954.py:115: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_df = pd.concat([result_df, working_success_df], ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght done:  13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 160\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_train, X_test, y_train, y_test\n\u001b[0;32m    159\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Data/HDFS_v1/Processed_data/processed_labeled_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 160\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_sequences_for_embedding_with_less_train_data_smart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 137\u001b[0m, in \u001b[0;36mcreate_sequences_for_embedding_with_less_train_data_smart\u001b[1;34m(path, length_of_sequences, number_to_choose, test_size, random_state)\u001b[0m\n\u001b[0;32m    135\u001b[0m success_df \u001b[38;5;241m=\u001b[39m data_df\u001b[38;5;241m.\u001b[39mloc[data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    136\u001b[0m fail_df \u001b[38;5;241m=\u001b[39m data_df\u001b[38;5;241m.\u001b[39mloc[data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 137\u001b[0m success_df \u001b[38;5;241m=\u001b[39m \u001b[43msmart_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuccess_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfail_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m train_success_df, test_success_df \u001b[38;5;241m=\u001b[39m train_test_split(success_df, test_size\u001b[38;5;241m=\u001b[39mtest_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    139\u001b[0m train_fail_df, test_fail_df \u001b[38;5;241m=\u001b[39m train_test_split(fail_df, test_size\u001b[38;5;241m=\u001b[39mtest_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n",
      "Cell \u001b[1;32mIn[6], line 113\u001b[0m, in \u001b[0;36msmart_selection\u001b[1;34m(x_train_success, x_train_fail, lengths, number_to_remove)\u001b[0m\n\u001b[0;32m    110\u001b[0m working_success_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeep_it\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    112\u001b[0m select_based_on_anomalies(working_success_df, working_fail_df, number_to_remove)\n\u001b[1;32m--> 113\u001b[0m \u001b[43mselect_remainder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworking_success_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_to_remove\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([result_df, working_success_df], ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlenght done: \u001b[39m\u001b[38;5;124m'\u001b[39m, length)\n",
      "Cell \u001b[1;32mIn[6], line 68\u001b[0m, in \u001b[0;36mselect_remainder\u001b[1;34m(working_success_df, number_to_remove)\u001b[0m\n\u001b[0;32m     65\u001b[0m chosen_vec \u001b[38;5;241m=\u001b[39m working_success_df_vectors[chosen_pos]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     66\u001b[0m unmarked_vectors \u001b[38;5;241m=\u001b[39m working_success_df_vectors[remaining_positions]\n\u001b[1;32m---> 68\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43munmarked_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchosen_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcosine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Step 3: Remove number_to_remove closest (excluding chosen itself)\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Get positions of remaining without chosen\u001b[39;00m\n\u001b[0;32m     72\u001b[0m positions_without_chosen \u001b[38;5;241m=\u001b[39m remaining_positions[remaining_positions \u001b[38;5;241m!=\u001b[39m chosen_pos]\n",
      "File \u001b[1;32mc:\\Users\\mathb\\Python\\envs\\diplomamunka\\lib\\site-packages\\scipy\\spatial\\distance.py:2649\u001b[0m, in \u001b[0;36mcdist\u001b[1;34m(XA, XB, metric, out, **kwargs)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             dm[i, j] \u001b[38;5;241m=\u001b[39m metric(XA[i], XB[j], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dm\n\u001b[1;32m-> 2649\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcdist\u001b[39m(XA, XB, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   2650\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2651\u001b[0m \u001b[38;5;124;03m    Compute distance between each pair of the two collections of inputs.\u001b[39;00m\n\u001b[0;32m   2652\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2942\u001b[0m \n\u001b[0;32m   2943\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2944\u001b[0m     \u001b[38;5;66;03m# You can also call this as:\u001b[39;00m\n\u001b[0;32m   2945\u001b[0m     \u001b[38;5;66;03m#     Y = cdist(XA, XB, 'test_abc')\u001b[39;00m\n\u001b[0;32m   2946\u001b[0m     \u001b[38;5;66;03m# where 'abc' is the metric being tested.  This computes the distance\u001b[39;00m\n\u001b[0;32m   2947\u001b[0m     \u001b[38;5;66;03m# between all pairs of vectors in XA and XB using the distance metric 'abc'\u001b[39;00m\n\u001b[0;32m   2948\u001b[0m     \u001b[38;5;66;03m# but with a more succinct, verifiable, but less efficient implementation.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def select_based_on_anomalies(working_success_df: pd.DataFrame, working_fail_df: pd.DataFrame, number_to_remove: int) -> None:\n",
    "    \"\"\"The first part of the smart selection, it performs the following algorithm: Choose one anomalous datapoint, \n",
    "    Select the closest non-anomalous point to it\n",
    "    Remove the closest number_to_remove many datapoints within the non-anomalous point's neighbourhood\n",
    "    \"\"\"    \n",
    "    working_success_df_vectors = np.vstack(working_success_df['Event_Count_Vector'].values)  # shape: (n1, d)\n",
    "    for _, row in working_fail_df.iterrows():\n",
    "        vec = row['Event_Count_Vector'].reshape(1, -1)  # shape: (1, d)\n",
    "\n",
    "        # Step 1: Compute cosine distances in bulk\n",
    "        distances = cdist(working_success_df_vectors, vec, metric='cosine').flatten()\n",
    "\n",
    "        # Mask out already marked vectors if necessary\n",
    "        idx_min = distances.argmin()\n",
    "        working_success_df.loc[idx_min, 'keep_it'] = 1\n",
    "\n",
    "        # Step 2: Find number_to_remove closest with keep_it == 0\n",
    "        mask = working_success_df['keep_it'] == 0\n",
    "        available_indices = working_success_df.index[mask]\n",
    "\n",
    "        if len(available_indices) > 0:\n",
    "            # Compute distances only for unmarked vectors\n",
    "            unmarked_vectors = working_success_df_vectors[mask.values]\n",
    "            target_vec = working_success_df_vectors[idx_min].reshape(1, -1)\n",
    "\n",
    "            distances_to_target = cdist(unmarked_vectors, target_vec, metric='cosine').flatten()\n",
    "\n",
    "            k = min(number_to_remove, len(distances_to_target))  # handle corner case\n",
    "            idxs_to_remove = available_indices[distances_to_target.argsort()[:k]]\n",
    "\n",
    "            working_success_df.loc[idxs_to_remove, 'keep_it'] = -1\n",
    "\n",
    "def select_remainder(working_success_df: pd.DataFrame, number_to_remove: int):\n",
    "    working_success_df_vectors = np.vstack(working_success_df['Event_Count_Vector'].values)  # shape: (n1, d)\n",
    "\n",
    "    while True:\n",
    "        mask_remaining = working_success_df['keep_it'] == 0\n",
    "        remaining_indices = working_success_df.index[mask_remaining]         # pandas indices\n",
    "        remaining_positions = np.where(mask_remaining.values)[0]             # numpy positions (0..n-1)\n",
    "\n",
    "        if len(remaining_indices) == 0:\n",
    "            break  # All done!\n",
    "\n",
    "        if len(remaining_indices) <= number_to_remove + 1:\n",
    "            # Not enough left to fully remove neighbors\n",
    "            chosen_pos = np.random.choice(remaining_positions)  # pick by position\n",
    "            chosen_idx = working_success_df.index[chosen_pos]   # map back to pandas index\n",
    "\n",
    "            working_success_df.loc[chosen_idx, 'keep_it'] = 1\n",
    "            other_idxs = remaining_indices.drop(chosen_idx)\n",
    "            working_success_df.loc[other_idxs, 'keep_it'] = -1\n",
    "            break  # Finished after this\n",
    "\n",
    "        # Step 1: Pick one randomly from remaining\n",
    "        chosen_pos = np.random.choice(remaining_positions)\n",
    "        chosen_idx = working_success_df.index[chosen_pos]\n",
    "        working_success_df.loc[chosen_idx, 'keep_it'] = 1\n",
    "\n",
    "        # Step 2: Compute distances from this vector to all remaining\n",
    "        chosen_vec = working_success_df_vectors[chosen_pos].reshape(1, -1)\n",
    "        unmarked_vectors = working_success_df_vectors[remaining_positions]\n",
    "\n",
    "        distances = cdist(unmarked_vectors, chosen_vec, metric='cosine').flatten()\n",
    "\n",
    "        # Step 3: Remove number_to_remove closest (excluding chosen itself)\n",
    "        # Get positions of remaining without chosen\n",
    "        positions_without_chosen = remaining_positions[remaining_positions != chosen_pos]\n",
    "\n",
    "        idxs_to_remove_pos = positions_without_chosen[\n",
    "            distances[remaining_positions != chosen_pos].argsort()[:number_to_remove]\n",
    "        ]\n",
    "\n",
    "        idxs_to_remove = working_success_df.index[idxs_to_remove_pos]  # map positions back to indices\n",
    "\n",
    "        working_success_df.loc[idxs_to_remove, 'keep_it'] = -1\n",
    "\n",
    "\n",
    "def smart_selection(x_train_success: pd.DataFrame, x_train_fail: pd.DataFrame, lengths: list = [13,25,35], number_to_remove: int=9):\n",
    "    '''This function is the implemented version of the potentially smarter selection to use less datapoints in training\n",
    "    x_train_success: The dataframe that only has non-anomaly type of data in it\n",
    "    x_train_fail: The dataframe that only has anomalous data in it\n",
    "    lengths: A list that consists of the lengths I want to divide my data into, an idea taken from stratified sampling\n",
    "    number_to_remove: An integer number, that describes how many datapoint I remove from the dataset after choosing one\n",
    "    '''\n",
    "    #Performing the stratified sampling inspired step\n",
    "    max_n = max(int(e[1:]) for sublist in x_train_success['Events'] for e in sublist)\n",
    "    x_train_success['Event_Count_Vector'] = x_train_success['Events'].apply(lambda x: count_vector(x, max_n))\n",
    "    x_train_fail['Event_Count_Vector'] = x_train_fail['Events'].apply(lambda x: count_vector(x, max_n))\n",
    "    x_train_success['lengths'] = x_train_success['Event_Count_Vector'].apply(lambda x: sum(x))\n",
    "    x_train_fail['lengths'] = x_train_fail['Event_Count_Vector'].apply(lambda x: sum(x))\n",
    "    \n",
    "    x_train_fail2 =x_train_fail.copy(deep = True)\n",
    "    result_df = pd.DataFrame(columns=['Event_Count_Vector', 'lengths', 'keep_it'])\n",
    "\n",
    "    for length in lengths:\n",
    "        mask = x_train_success['lengths'] <= length\n",
    "        working_success_df = x_train_success[mask].copy(deep=True)\n",
    "        working_success_df = working_success_df.reset_index(drop=True)\n",
    "        x_train_success = x_train_success[~mask]\n",
    "\n",
    "        mask = x_train_fail2['lengths'] <= length\n",
    "        working_fail_df = x_train_fail2[mask].copy(deep=True)\n",
    "        x_train_fail2 = x_train_fail2[~mask]\n",
    "\n",
    "        working_success_df['keep_it'] = 0\n",
    "\n",
    "        select_based_on_anomalies(working_success_df, working_fail_df, number_to_remove)\n",
    "        select_remainder(working_success_df, number_to_remove)\n",
    "\n",
    "        result_df = pd.concat([result_df, working_success_df], ignore_index = True)\n",
    "        print('lenght done: ', length)\n",
    "    result_df.drop(columns='Event_Count_Vector', inplace=True)\n",
    "    x_train_fail.drop(columns = 'Event_Count_Vector', inplace = True)\n",
    "    mask = result_df['keep_it'] == 1\n",
    "    result_df = result_df[mask]\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def create_sequences_for_embedding_with_less_train_data_smart(path: str, length_of_sequences: int, number_to_choose: int=9,  test_size: float=0.2, random_state: int=42):\n",
    "    #Loading in the data\n",
    "    data_df = pd.read_csv(path)\n",
    "    #Converting the labels to binary numbers, 0 for success, 1 for failure\n",
    "    mask = data_df['Final Label'] == 'Success'\n",
    "    data_df.loc[mask, 'label'] = 0\n",
    "    data_df.loc[~mask, 'label'] = 1\n",
    "    #I do not need the index column\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "    data_df['Events']  = data_df['New Event ID'].apply(ast.literal_eval)\n",
    "\n",
    "    success_df = data_df.loc[data_df['label'] == 0].copy(deep=True)\n",
    "    fail_df = data_df.loc[data_df['label'] == 1].copy(deep=True)\n",
    "    success_df = smart_selection(success_df, fail_df)\n",
    "    train_success_df, test_success_df = train_test_split(success_df, test_size=test_size, shuffle=True, random_state=random_state)\n",
    "    train_fail_df, test_fail_df = train_test_split(fail_df, test_size=test_size, shuffle=True, random_state=random_state)\n",
    "    #Now concatenate the dataframes\n",
    "    train_df = pd.concat([train_success_df, train_fail_df], ignore_index=True).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    test_df = pd.concat([test_success_df, test_fail_df], ignore_index=True).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #Calculating the maximum value of the En type events\n",
    "    max_n = max(int(e[1:]) for sublist in data_df['Events'] for e in sublist)\n",
    "    train_df['Event_sequences'] = train_df['Events'].apply(lambda x: sequence_for_embedding(x, max_n, length_of_sequences))\n",
    "    train_df.drop(columns=['Unnamed: 0', 'BlockId', 'New Event ID', 'Final Label', 'Events'], inplace=True)\n",
    "\n",
    "    test_df['Event_sequences'] = test_df['Events'].apply(lambda x: sequence_for_embedding(x, max_n, length_of_sequences))\n",
    "    test_df.drop(columns=['Unnamed: 0', 'BlockId', 'New Event ID', 'Final Label', 'Events'], inplace=True)\n",
    "    #Separate the dataframes based on the label and perform the train_test_split\n",
    "    X_train, y_train = create_arrays_from_sequences(train_df)\n",
    "    X_test, y_test = create_arrays_from_sequences(test_df)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "path = '../Data/HDFS_v1/Processed_data/processed_labeled_data.csv'\n",
    "X_train, X_test, y_train, y_test = create_sequences_for_embedding_with_less_train_data_smart(path, 50)\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e366733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matrix(event_list, n):\n",
    "    matrix = np.zeros([len(event_list),n])\n",
    "    i = 0\n",
    "    for event in event_list:\n",
    "        index = int(event[1:]) - 1\n",
    "        if 0 <= index < n:\n",
    "            if i > 0:\n",
    "                matrix[i] = matrix[i-1]\n",
    "            matrix[i, index] += 1\n",
    "            i += 1\n",
    "    return matrix\n",
    "\n",
    "def create_arrays_from_df_easier_v2(data_df: pd.DataFrame, length_of_matrices: int=50) -> Tuple[np.array, np.array]:\n",
    "    X, y = [], []\n",
    "    for _, row in data_df.iterrows():\n",
    "        seq = row['Event_Count_Matrix']\n",
    "        label = row['label']\n",
    "        if seq.shape[0] < length_of_matrices:\n",
    "            helper_matrix = np.zeros((length_of_matrices, seq.shape[1]))\n",
    "            helper_matrix[:seq.shape[0]] = seq\n",
    "            helper_matrix[seq.shape[0]:] = seq[-1]\n",
    "        if seq.shape[0] >= length_of_matrices:\n",
    "            helper_matrix = seq[:length_of_matrices]\n",
    "        X.append(helper_matrix)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def train_test_split_count_matrix_for_LSTM_easier_padding_with_less_data_smart(path: str, length_of_matrices: int, version: int=1,sequence_col: str = 'Event_Count_Matrix', label_col: str='label', test_size: float=0.2,number_to_choose:int=9, BGL: bool=False, random_state: int=42):\n",
    "    #Loading in the data\n",
    "    data_df = pd.read_csv(path)\n",
    "    \n",
    "    #Converting the labels to binary numbers, 0 for success, 1 for failure\n",
    "    mask = data_df['Final Label'] == 'Success'\n",
    "    data_df.loc[mask, 'label'] = 0\n",
    "    data_df.loc[~mask, 'label'] = 1\n",
    "    #I do not need the index column\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "    data_df['Events']  = data_df['New Event ID'].apply(ast.literal_eval)\n",
    "\n",
    "    success_df = data_df.loc[data_df['label'] == 0].copy(deep=True)\n",
    "    fail_df = data_df.loc[data_df['label'] == 1].copy(deep=True)\n",
    "    success_df = smart_selection(success_df, fail_df)\n",
    "    train_success_df, test_success_df = train_test_split(success_df, test_size=test_size, shuffle=True, random_state=random_state)\n",
    "    train_fail_df, test_fail_df = train_test_split(fail_df, test_size=test_size, shuffle=True, random_state=random_state)\n",
    "    #Now concatenate the dataframes\n",
    "    train_df = pd.concat([train_success_df, train_fail_df], ignore_index=True).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    test_df = pd.concat([test_success_df, test_fail_df], ignore_index=True).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    max_n = max(int(e[1:]) for sublist in data_df['Events'] for e in sublist)\n",
    "    train_df['Event_sequences'] = train_df['Events'].apply(lambda x: count_matrix(x, max_n))\n",
    "    train_df.drop(columns=['Unnamed: 0', 'BlockId', 'New Event ID', 'Final Label', 'Events'], inplace=True)\n",
    "\n",
    "    test_df['Event_sequences'] = test_df['Events'].apply(lambda x: count_matrix(x, max_n))\n",
    "    test_df.drop(columns=['Unnamed: 0', 'BlockId', 'New Event ID', 'Final Label', 'Events'], inplace=True)\n",
    "\n",
    "\n",
    "    #Now let's perform the matrix creating magic\n",
    "    if version == 1:\n",
    "        X_train, y_train = create_arrays_from_df_easier_v1(train_df, length_of_matrices)\n",
    "        X_test, y_test = create_arrays_from_df_easier_v1(test_df, length_of_matrices)\n",
    "    if version == 2:\n",
    "        X_train, y_train = create_arrays_from_df_easier_v2(train_df, length_of_matrices)\n",
    "        X_test, y_test = create_arrays_from_df_easier_v2(test_df, length_of_matrices)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5516d0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17580\\993504907.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split_count_matrix_for_LSTM_easier_padding_with_less_data_smart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17580\\2104650129.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(path, length_of_matrices, version, sequence_col, label_col, test_size, number_to_choose, BGL, random_state)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mdata_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Events'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'New Event ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0msuccess_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mfail_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0msuccess_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuccess_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfail_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mtrain_success_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_success_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuccess_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mtrain_fail_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_fail_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfail_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m#Now concatenate the dataframes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17580\\902015954.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x_train_success, x_train_fail, lengths, number_to_remove)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mx_train_fail2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train_fail2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mworking_success_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keep_it'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mselect_based_on_anomalies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworking_success_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworking_fail_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_to_remove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mselect_remainder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworking_success_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_to_remove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mresult_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworking_success_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17580\\902015954.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(working_success_df, working_fail_df, number_to_remove)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworking_success_df_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cosine'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Mask out already marked vectors if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0midx_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mworking_success_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'keep_it'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# Step 2: Find number_to_remove closest with keep_it == 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworking_success_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keep_it'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathb\\Python\\envs\\diplomamunka\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\mathb\\Python\\envs\\diplomamunka\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1939\u001b[0m         \u001b[1;31m# align and set the values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1940\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtake_split_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1941\u001b[0m             \u001b[1;31m# We have to operate column-wise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1942\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1943\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathb\\Python\\envs\\diplomamunka\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   2031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2032\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2033\u001b[0m             \u001b[1;31m# scalar value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2034\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0milocs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2035\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_single_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\mathb\\Python\\envs\\diplomamunka\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[0;32m   2160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2161\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m             \u001b[1;31m# set value into the column (first attempting to operate inplace, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2163\u001b[0m             \u001b[1;31m#  falling back to casting if necessary)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2164\u001b[1;33m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2165\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvoid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2166\u001b[0m                 \u001b[1;31m# This means we're expanding, with multiple columns, e.g.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2167\u001b[0m                 \u001b[1;31m#     df = pd.DataFrame({'A': [1,2,3], 'B': [4,5,6]})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathb\\Python\\envs\\diplomamunka\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\mathb\\Python\\envs\\diplomamunka\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1748\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1749\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot index by location index with a non-integer key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1751\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1752\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1754\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathb\\Python\\envs\\diplomamunka\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1679\u001b[0m         \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1680\u001b[0m         \u001b[0mIndexError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1681\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;34m'key'\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0mposition\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;34m'axis'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1682\u001b[0m         \"\"\"\n\u001b[1;32m-> 1683\u001b[1;33m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1685\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathb\\Python\\envs\\diplomamunka\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis)\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[0maxis_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0maxis_number\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis_number\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_count_matrix_for_LSTM_easier_padding_with_less_data_smart(path, 50, version=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "989c983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [13, 25, 35]\n",
    "number_to_remove = 9\n",
    "x_train_success['lengths'] = x_train_success['Event_Count_Vector'].apply(lambda x: sum(x))\n",
    "x_train_fail['lengths'] = x_train_fail['Event_Count_Vector'].apply(lambda x: sum(x))\n",
    "\n",
    "mask = x_train_success['lengths'] <= 13\n",
    "x_train_success = x_train_success[~mask]\n",
    "\n",
    "mask = x_train_fail['lengths'] <= 13\n",
    "x_train_fail = x_train_fail[~mask]\n",
    "\n",
    "\n",
    "\n",
    "mask = (x_train_success['lengths'] <= 25)\n",
    "working_success_df = x_train_success[mask].copy(deep=True)\n",
    "\n",
    "mask = (x_train_fail['lengths'] <= 25)\n",
    "working_fail_df = x_train_fail[mask].copy(deep=True)\n",
    "\n",
    "working_success_df['keep_it'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d2adc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293783"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = working_success_df['keep_it'] == 0\n",
    "len(mask.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "100102ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_Count_Vector</th>\n",
       "      <th>lengths</th>\n",
       "      <th>keep_it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30498</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404325</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99900</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255959</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412174</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56040</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112672</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374037</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134768</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293783 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Event_Count_Vector  lengths  keep_it\n",
       "30498   [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     19.0      0.0\n",
       "404325  [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     19.0      0.0\n",
       "99900   [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     25.0      0.0\n",
       "255959  [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     19.0      0.0\n",
       "412174  [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     19.0      0.0\n",
       "...                                                   ...      ...      ...\n",
       "56040   [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     19.0      0.0\n",
       "112672  [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     19.0      0.0\n",
       "374037  [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     19.0      0.0\n",
       "134768  [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     19.0      0.0\n",
       "0                                                     NaN      NaN      1.0\n",
       "\n",
       "[293783 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_success_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21a305fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(working_success_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7200c3a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 48 and the array at index 293782 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine, cdist\n\u001b[1;32m----> 6\u001b[0m working_success_df_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworking_success_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEvent_Count_Vector\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape: (n1, d)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m working_fail_df\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[1;32mc:\\Users\\mathb\\Python\\envs\\diplomamunka\\lib\\site-packages\\numpy\\_core\\shape_base.py:287\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    286\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m (arrs,)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 48 and the array at index 293782 has size 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine, cdist\n",
    "\n",
    "\n",
    "working_success_df_vectors = np.vstack(working_success_df['Event_Count_Vector'].values)  # shape: (n1, d)\n",
    "i = 0\n",
    "for _, row in working_fail_df.iterrows():\n",
    "    vec = row['Event_Count_Vector'].reshape(1, -1)  # shape: (1, d)\n",
    "\n",
    "    # Step 1: Compute cosine distances in bulk\n",
    "    distances = cdist(working_success_df_vectors, vec, metric='cosine').flatten()\n",
    "\n",
    "    # Mask out already marked vectors if necessary\n",
    "    idx_min = distances.argmin()\n",
    "    working_success_df.loc[idx_min, 'keep_it'] = 1\n",
    "\n",
    "    # Step 2: Find number_to_remove closest with keep_it == 0\n",
    "    mask = working_success_df['keep_it'] == 0\n",
    "    available_indices = working_success_df.index[mask]\n",
    "\n",
    "    if len(available_indices) > 0:\n",
    "        # Compute distances only for unmarked vectors\n",
    "        unmarked_vectors = working_success_df_vectors[mask.values]\n",
    "        target_vec = working_success_df_vectors[idx_min].reshape(1, -1)\n",
    "\n",
    "        distances_to_target = cdist(unmarked_vectors, target_vec, metric='cosine').flatten()\n",
    "\n",
    "        k = min(number_to_remove, len(distances_to_target))  # handle corner case\n",
    "        idxs_to_remove = available_indices[distances_to_target.argsort()[:k]]\n",
    "\n",
    "        working_success_df.loc[idxs_to_remove, 'keep_it'] = -1\n",
    "    i += 1\n",
    "    if i%10==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8386e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations done: 10\n",
      "Iterations done: 20\n",
      "Iterations done: 30\n",
      "Iterations done: 40\n",
      "Iterations done: 50\n",
      "Iterations done: 60\n",
      "Iterations done: 70\n",
      "Iterations done: 80\n",
      "Iterations done: 90\n",
      "Iterations done: 100\n",
      "Iterations done: 110\n",
      "Iterations done: 120\n",
      "Iterations done: 130\n",
      "Iterations done: 140\n",
      "Iterations done: 150\n",
      "Iterations done: 160\n",
      "Iterations done: 170\n",
      "Iterations done: 180\n",
      "Iterations done: 190\n",
      "Iterations done: 200\n",
      "Iterations done: 210\n",
      "Iterations done: 220\n",
      "Iterations done: 230\n",
      "Iterations done: 240\n",
      "Iterations done: 250\n",
      "Iterations done: 260\n",
      "Iterations done: 270\n",
      "Iterations done: 280\n",
      "Iterations done: 290\n",
      "Iterations done: 300\n",
      "Iterations done: 310\n",
      "Iterations done: 320\n",
      "Iterations done: 330\n",
      "Iterations done: 340\n",
      "Iterations done: 350\n",
      "Iterations done: 360\n",
      "Iterations done: 370\n",
      "Iterations done: 380\n",
      "Iterations done: 390\n",
      "Iterations done: 400\n",
      "Iterations done: 410\n",
      "Iterations done: 420\n",
      "Iterations done: 430\n",
      "Iterations done: 440\n",
      "Iterations done: 450\n",
      "Iterations done: 460\n",
      "Iterations done: 470\n",
      "Iterations done: 480\n",
      "Iterations done: 490\n",
      "Iterations done: 500\n",
      "Iterations done: 510\n",
      "Iterations done: 520\n",
      "Iterations done: 530\n",
      "Iterations done: 540\n",
      "Iterations done: 550\n",
      "Iterations done: 560\n",
      "Iterations done: 570\n",
      "Iterations done: 580\n",
      "Iterations done: 590\n",
      "Iterations done: 600\n",
      "Iterations done: 610\n",
      "Iterations done: 620\n",
      "Iterations done: 630\n",
      "Iterations done: 640\n",
      "Iterations done: 650\n",
      "Iterations done: 660\n",
      "Iterations done: 670\n",
      "Iterations done: 680\n",
      "Iterations done: 690\n",
      "Iterations done: 700\n",
      "Iterations done: 710\n",
      "Iterations done: 720\n",
      "Iterations done: 730\n",
      "Iterations done: 740\n",
      "Iterations done: 750\n",
      "Iterations done: 760\n",
      "Iterations done: 770\n",
      "Iterations done: 780\n",
      "Iterations done: 790\n",
      "Iterations done: 800\n",
      "Iterations done: 810\n",
      "Iterations done: 820\n",
      "Iterations done: 830\n",
      "Iterations done: 840\n",
      "Iterations done: 850\n",
      "Iterations done: 860\n",
      "Iterations done: 870\n",
      "Iterations done: 880\n",
      "Iterations done: 890\n",
      "Iterations done: 900\n",
      "Iterations done: 910\n",
      "Iterations done: 920\n",
      "Iterations done: 930\n",
      "Iterations done: 940\n",
      "Iterations done: 950\n",
      "Iterations done: 960\n",
      "Iterations done: 970\n",
      "Iterations done: 980\n",
      "Iterations done: 990\n",
      "Iterations done: 1000\n",
      "Iterations done: 1010\n",
      "Iterations done: 1020\n",
      "Iterations done: 1030\n",
      "Iterations done: 1040\n",
      "Iterations done: 1050\n",
      "Iterations done: 1060\n",
      "Iterations done: 1070\n",
      "Iterations done: 1080\n",
      "Iterations done: 1090\n",
      "Iterations done: 1100\n",
      "Iterations done: 1110\n",
      "Iterations done: 1120\n",
      "Iterations done: 1130\n",
      "Iterations done: 1140\n",
      "Iterations done: 1150\n",
      "Iterations done: 1160\n",
      "Iterations done: 1170\n",
      "Iterations done: 1180\n",
      "Iterations done: 1190\n",
      "Iterations done: 1200\n",
      "Iterations done: 1210\n",
      "Iterations done: 1220\n",
      "Iterations done: 1230\n",
      "Iterations done: 1240\n",
      "Iterations done: 1250\n",
      "Iterations done: 1260\n",
      "Iterations done: 1270\n",
      "Iterations done: 1280\n",
      "Iterations done: 1290\n",
      "Iterations done: 1300\n",
      "Iterations done: 1310\n",
      "Iterations done: 1320\n",
      "Iterations done: 1330\n",
      "Iterations done: 1340\n",
      "Iterations done: 1350\n",
      "Iterations done: 1360\n",
      "Iterations done: 1370\n",
      "Iterations done: 1380\n",
      "Iterations done: 1390\n",
      "Iterations done: 1400\n",
      "Iterations done: 1410\n",
      "Iterations done: 1420\n",
      "Iterations done: 1430\n",
      "Iterations done: 1440\n",
      "Iterations done: 1450\n",
      "Iterations done: 1460\n",
      "Iterations done: 1470\n",
      "Iterations done: 1480\n",
      "Iterations done: 1490\n",
      "Iterations done: 1500\n",
      "Iterations done: 1510\n",
      "Iterations done: 1520\n",
      "Iterations done: 1530\n",
      "Iterations done: 1540\n",
      "Iterations done: 1550\n",
      "Iterations done: 1560\n",
      "Iterations done: 1570\n",
      "Iterations done: 1580\n",
      "Iterations done: 1590\n",
      "Iterations done: 1600\n",
      "Iterations done: 1610\n",
      "Iterations done: 1620\n",
      "Iterations done: 1630\n",
      "Iterations done: 1640\n",
      "Iterations done: 1650\n",
      "Iterations done: 1660\n",
      "Iterations done: 1670\n",
      "Iterations done: 1680\n",
      "Iterations done: 1690\n",
      "Iterations done: 1700\n",
      "Iterations done: 1710\n",
      "Iterations done: 1720\n",
      "Iterations done: 1730\n",
      "Iterations done: 1740\n",
      "Iterations done: 1750\n",
      "Iterations done: 1760\n",
      "Iterations done: 1770\n",
      "Iterations done: 1780\n",
      "Iterations done: 1790\n",
      "Iterations done: 1800\n",
      "Iterations done: 1810\n",
      "Iterations done: 1820\n",
      "Iterations done: 1830\n",
      "Iterations done: 1840\n",
      "Iterations done: 1850\n",
      "Iterations done: 1860\n",
      "Iterations done: 1870\n",
      "Iterations done: 1880\n",
      "Iterations done: 1890\n",
      "Iterations done: 1900\n",
      "Iterations done: 1910\n",
      "Iterations done: 1920\n",
      "Iterations done: 1930\n",
      "Iterations done: 1940\n",
      "Iterations done: 1950\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Precompute vectors as numpy array for speed\n",
    "working_success_df_vectors = np.vstack(working_success_df['Event_Count_Vector'].values)  # shape: (n1, d)\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    mask_remaining = working_success_df['keep_it'] == 0\n",
    "    remaining_indices = working_success_df.index[mask_remaining]         # pandas indices\n",
    "    remaining_positions = np.where(mask_remaining.values)[0]             # numpy positions (0..n-1)\n",
    "\n",
    "    if len(remaining_indices) == 0:\n",
    "        break  # All done!\n",
    "\n",
    "    if len(remaining_indices) <= number_to_remove + 1:\n",
    "        # Not enough left to fully remove neighbors\n",
    "        chosen_pos = np.random.choice(remaining_positions)  # pick by position\n",
    "        chosen_idx = working_success_df.index[chosen_pos]   # map back to pandas index\n",
    "\n",
    "        working_success_df.loc[chosen_idx, 'keep_it'] = 1\n",
    "        other_idxs = remaining_indices.drop(chosen_idx)\n",
    "        working_success_df.loc[other_idxs, 'keep_it'] = -1\n",
    "        break  # Finished after this\n",
    "\n",
    "    # Step 1: Pick one randomly from remaining\n",
    "    chosen_pos = np.random.choice(remaining_positions)\n",
    "    chosen_idx = working_success_df.index[chosen_pos]\n",
    "    working_success_df.loc[chosen_idx, 'keep_it'] = 1\n",
    "\n",
    "    # Step 2: Compute distances from this vector to all remaining\n",
    "    chosen_vec = working_success_df_vectors[chosen_pos].reshape(1, -1)\n",
    "    unmarked_vectors = working_success_df_vectors[remaining_positions]\n",
    "\n",
    "    distances = cdist(unmarked_vectors, chosen_vec, metric='cosine').flatten()\n",
    "\n",
    "    # Step 3: Remove number_to_remove closest (excluding chosen itself)\n",
    "    # Get positions of remaining without chosen\n",
    "    positions_without_chosen = remaining_positions[remaining_positions != chosen_pos]\n",
    "\n",
    "    idxs_to_remove_pos = positions_without_chosen[\n",
    "        distances[remaining_positions != chosen_pos].argsort()[:number_to_remove]\n",
    "    ]\n",
    "\n",
    "    idxs_to_remove = working_success_df.index[idxs_to_remove_pos]  # map positions back to indices\n",
    "\n",
    "    working_success_df.loc[idxs_to_remove, 'keep_it'] = -1\n",
    "\n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Iterations done: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d91b1ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_Count_Vector</th>\n",
       "      <th>lengths</th>\n",
       "      <th>keep_it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466622</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254390</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210539</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388170</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335133</th>\n",
       "      <td>[3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Event_Count_Vector  lengths  keep_it\n",
       "466622  [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     13.0        1\n",
       "254390  [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     13.0       -1\n",
       "210539  [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     13.0       -1\n",
       "388170  [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     13.0       -1\n",
       "335133  [3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...     13.0       -1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_success_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6eb472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diplomamunka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
