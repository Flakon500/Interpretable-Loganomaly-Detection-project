{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function that creates the count vectors\n",
    "def count_vector(event_list, n):\n",
    "    vector = np.zeros(n)\n",
    "    for event in event_list:\n",
    "        index = int(event[1:]) - 1  # Convert 'E1' to 0, 'E2' to 1, etc.\n",
    "        if 0 <= index < n:\n",
    "            vector[index] += 1\n",
    "    return vector\n",
    "\n",
    "def one_hot_encoded_matrix(event_list, n):\n",
    "    matrix = np.zeros([len(event_list), n])\n",
    "    i = 0\n",
    "    for event in event_list:\n",
    "        index = int(event[1:]) - 1\n",
    "        if 0 <= index < n:\n",
    "            matrix[i,index] = 1\n",
    "            i += 1\n",
    "    return matrix\n",
    "\n",
    "def count_matrix(event_list, n):\n",
    "    matrix = np.zeros([len(event_list),n])\n",
    "    i = 0\n",
    "    for event in event_list:\n",
    "        index = int(event[1:]) - 1\n",
    "        if 0 <= index < n:\n",
    "            if i > 0:\n",
    "                matrix[i] = matrix[i-1]\n",
    "            matrix[i, index] += 1\n",
    "            i += 1\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_for_data(path: str, test_size: float):\n",
    "    #Loading in the data\n",
    "    data_df = pd.read_csv(path)\n",
    "    #Converting the labels to binary numbers, 0 for success, 1 for failure\n",
    "    mask = data_df['Final Label'] == 'Success'\n",
    "    data_df.loc[mask, 'label'] = 0\n",
    "    data_df.loc[~mask, 'label'] = 1\n",
    "    #I do not need the index column\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "\n",
    "    #Once converted, the strings of the event IDs are also unnecessary\n",
    "    data_df['Events']  = data_df['New Event ID'].apply(ast.literal_eval)\n",
    "    #Calculating the maximum value of the En type events\n",
    "    max_n = max(int(e[1:]) for sublist in data_df['Events'] for e in sublist)\n",
    "    data_df['Event_Count_Vector'] = data_df['Events'].apply(lambda x: count_vector(x, max_n))\n",
    "    data_df.drop(columns=['Final Label', 'Unnamed: 0', 'New Event ID', 'Events', 'BlockId'], inplace=True)\n",
    "    count_vector_df = pd.DataFrame(data_df['Event_Count_Vector'].tolist(), index=data_df.index)\n",
    "\n",
    "    #For logistic regression\n",
    "    count_vector_df.columns = [f'feature_{i+1}' for i in range(count_vector_df.shape[1])]\n",
    "    data_df = pd.concat([data_df, count_vector_df], axis=1)\n",
    "    data_df.drop(columns='Event_Count_Vector', inplace = True)\n",
    "\n",
    "    success_df = data_df.loc[data_df['label'] == 0].copy(deep=True)\n",
    "    fail_df = data_df.loc[data_df['label'] == 1].copy(deep=True)\n",
    "    success_df_label = success_df['label'].copy(deep=True)\n",
    "    success_df.drop(columns='label', inplace=True)\n",
    "    fail_df_label = fail_df['label'].copy(deep=True)\n",
    "    fail_df.drop(columns='label', inplace=True)\n",
    "    x_train_success, x_test_success,y_train_success, y_test_success = train_test_split(success_df, success_df_label, test_size=test_size, shuffle=True, random_state=42)\n",
    "    x_train_fail, x_test_fail, y_train_fail, y_test_fail = train_test_split(fail_df, fail_df_label, test_size=test_size, shuffle = True, random_state=42)\n",
    "    x_train = pd.concat([x_train_success, x_train_fail], ignore_index=True)\n",
    "    x_test = pd.concat([x_test_success, x_test_fail], ignore_index=True)\n",
    "    y_train = pd.concat([y_train_success, y_train_fail], ignore_index=True)\n",
    "    y_test = pd.concat([y_test_success, y_test_fail], ignore_index=True)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_for_data_autoencoder(path: str, test_size: float, semisupervised: bool):\n",
    "    #Loading in the data\n",
    "    data_df = pd.read_csv(path)\n",
    "    #Converting the labels to binary numbers, 0 for success, 1 for failure\n",
    "    mask = data_df['Final Label'] == 'Success'\n",
    "    data_df.loc[mask, 'label'] = 0\n",
    "    data_df.loc[~mask, 'label'] = 1\n",
    "    #I do not need the index column\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "\n",
    "    #Once converted, the strings of the event IDs are also unnecessary\n",
    "    data_df['Events']  = data_df['New Event ID'].apply(ast.literal_eval)\n",
    "    #Calculating the maximum value of the En type events\n",
    "    max_n = max(int(e[1:]) for sublist in data_df['Events'] for e in sublist)\n",
    "    data_df['Event_Count_Vector'] = data_df['Events'].apply(lambda x: count_vector(x, max_n))\n",
    "    data_df.drop(columns=['Final Label', 'Unnamed: 0', 'New Event ID', 'Events', 'BlockId'], inplace=True)\n",
    "    count_vector_df = pd.DataFrame(data_df['Event_Count_Vector'].tolist(), index=data_df.index)\n",
    "\n",
    "    #For logistic regression\n",
    "    count_vector_df.columns = [f'feature_{i+1}' for i in range(count_vector_df.shape[1])]\n",
    "    data_df = pd.concat([data_df, count_vector_df], axis=1)\n",
    "    data_df.drop(columns='Event_Count_Vector', inplace = True)\n",
    "\n",
    "\n",
    "    success_df = data_df.loc[data_df['label'] == 0].copy(deep=True)\n",
    "    fail_df = data_df.loc[data_df['label'] == 1].copy(deep=True)\n",
    "    success_df_label = success_df['label'].copy(deep=True)\n",
    "    success_df.drop(columns='label', inplace=True)\n",
    "    fail_df_label = fail_df['label'].copy(deep=True)\n",
    "    fail_df.drop(columns='label', inplace=True)\n",
    "    x_train_success, x_test_success,y_train_success, y_test_success = train_test_split(success_df, success_df_label, test_size=test_size, shuffle=True, random_state=42)\n",
    "    x_train_fail, x_test_fail, y_train_fail, y_test_fail = train_test_split(fail_df, fail_df_label, test_size=test_size, shuffle = True, random_state=42)\n",
    "    x_train = pd.concat([x_train_success, x_train_fail], ignore_index=True)\n",
    "    x_test = pd.concat([x_test_success, x_test_fail], ignore_index=True)\n",
    "    y_train = pd.concat([y_train_success, y_train_fail], ignore_index=True)\n",
    "    y_test = pd.concat([y_test_success, y_test_fail], ignore_index=True)\n",
    "    if semisupervised:\n",
    "        return x_train_success, y_train_success, x_test_success, y_test_success, x_train_fail, y_train_fail, x_test_fail, y_test_fail\n",
    "    else:\n",
    "        return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_count_matrix(path: str, test_size: float, semisupervised: bool):\n",
    "    #Loading in the data\n",
    "    data_df = pd.read_csv(path)\n",
    "    #Converting the labels to binary numbers, 0 for success, 1 for failure\n",
    "    mask = data_df['Final Label'] == 'Success'\n",
    "    data_df.loc[mask, 'label'] = 0\n",
    "    data_df.loc[~mask, 'label'] = 1\n",
    "    #I do not need the index column\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "    \n",
    "    data_df['Events']  = data_df['New Event ID'].apply(ast.literal_eval)\n",
    "    #Calculating the maximum value of the En type events\n",
    "    max_n = max(int(e[1:]) for sublist in data_df['Events'] for e in sublist)\n",
    "    data_df['Event_Count_Vector'] = data_df['Events'].apply(lambda x: count_vector(x, max_n))\n",
    "    data_df.drop(columns=['Final Label', 'Unnamed: 0', 'New Event ID', 'Events', 'BlockId'], inplace=True)\n",
    "    count_vector_df = pd.DataFrame(data_df['Event_Count_Vector'].tolist(), index=data_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_count_matrix_baseline(path: str, test_size: float, semisupervised: bool=False):\n",
    "    #Loading in the data\n",
    "    data_df = pd.read_csv(path)\n",
    "    #Converting the labels to binary numbers, 0 for success, 1 for failure\n",
    "    mask = data_df['Final Label'] == 'Success'\n",
    "    data_df.loc[mask, 'label'] = 0\n",
    "    data_df.loc[~mask, 'label'] = 1\n",
    "    #I do not need the index column\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "\n",
    "    data_df['Events']  = data_df['New Event ID'].apply(ast.literal_eval)\n",
    "    #Calculating the maximum value of the En type events\n",
    "    max_n = max(int(e[1:]) for sublist in data_df['Events'] for e in sublist)\n",
    "    data_df['Event_Count_Matrix'] = data_df['Events'].apply(lambda x: count_matrix(x, max_n))\n",
    "    success_df = data_df.loc[data_df['label'] == 0].copy(deep=True)\n",
    "    fail_df = data_df.loc[data_df['label'] == 1].copy(deep=True)\n",
    "    success_df_label = success_df['label'].copy(deep=True)\n",
    "    success_df.drop(columns='label', inplace=True)\n",
    "    fail_df_label = fail_df['label'].copy(deep=True)\n",
    "    fail_df.drop(columns='label', inplace=True)\n",
    "    x_train_success, x_test_success, y_train_success, y_test_success = train_test_split(success_df, success_df_label, test_size=test_size, shuffle=True, random_state=42)\n",
    "    x_train_fail, x_test_fail, y_train_fail, y_test_fail = train_test_split(fail_df, fail_df_label, test_size=test_size, shuffle = True, random_state=42)\n",
    "    \n",
    "    x_train_success_np = np.vstack(x_train_success['Event_Count_Matrix'].values)\n",
    "    x_train_fail_np = np.vstack(x_train_fail['Event_Count_Matrix'].values)\n",
    "    x_test_success_np = x_test_success['Event_Count_Matrix'].to_list()\n",
    "    x_test_fail_np = x_test_fail['Event_Count_Matrix'].to_list()\n",
    "    x_train_np = np.vstack((x_train_success_np, x_train_fail_np))\n",
    "    x_test_np = x_test_success_np + x_test_fail_np\n",
    "    y_test_success_np = y_train_success.to_list()\n",
    "    y_test_fail_np = y_test_fail.to_list()\n",
    "    y_test_np = y_test_success_np + y_test_fail_np\n",
    "    if semisupervised:\n",
    "        return x_train_success_np, x_test_np, y_test_np\n",
    "    else:\n",
    "        return x_train_np, x_test_np, y_test_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_test = train_test_split_count_matrix_baseline('../Data/HDFS_v1/Processed_data/processed_labeled_data.csv', 0.2)\n",
    "x_train2, x_test2, y_test2 = train_test_split_count_matrix_baseline('../Data/HDFS_v1/Processed_data/processed_labeled_data.csv', 0.2, semisupervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diplomamunka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
