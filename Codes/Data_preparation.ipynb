{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function that creates the count vectors\n",
    "def count_vector(event_list, n):\n",
    "    vector = np.zeros(n)\n",
    "    for event in event_list:\n",
    "        index = int(event[1:]) - 1  # Convert 'E1' to 0, 'E2' to 1, etc.\n",
    "        if 0 <= index < n:\n",
    "            vector[index] += 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_for_data(path: str, test_size: float):\n",
    "    #Loading in the data\n",
    "    data_df = pd.read_csv(path)\n",
    "    #Converting the labels to binary numbers, 0 for success, 1 for failure\n",
    "    mask = data_df['Final Label'] == 'Success'\n",
    "    data_df.loc[mask, 'label'] = 0\n",
    "    data_df.loc[~mask, 'label'] = 1\n",
    "    #I do not need the index column\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "\n",
    "    #Once converted, the strings of the event IDs are also unnecessary\n",
    "    data_df['Events']  = data_df['New Event ID'].apply(ast.literal_eval)\n",
    "    #Calculating the maximum value of the En type events\n",
    "    max_n = max(int(e[1:]) for sublist in data_df['Events'] for e in sublist)\n",
    "    data_df['Event_Count_Vector'] = data_df['Events'].apply(lambda x: count_vector(x, max_n))\n",
    "    data_df.drop(columns=['Final Label', 'Unnamed: 0', 'New Event ID', 'Events', 'BlockId'], inplace=True)\n",
    "    count_vector_df = pd.DataFrame(data_df['Event_Count_Vector'].tolist(), index=data_df.index)\n",
    "\n",
    "    #For logistic regression\n",
    "    count_vector_df.columns = [f'feature_{i+1}' for i in range(count_vector_df.shape[1])]\n",
    "    data_df = pd.concat([data_df, count_vector_df], axis=1)\n",
    "    data_df.drop(columns='Event_Count_Vector', inplace = True)\n",
    "\n",
    "    success_df = data_df.loc[data_df['label'] == 0].copy(deep=True)\n",
    "    fail_df = data_df.loc[data_df['label'] == 1].copy(deep=True)\n",
    "    success_df_label = success_df['label'].copy(deep=True)\n",
    "    success_df.drop(columns='label', inplace=True)\n",
    "    fail_df_label = fail_df['label'].copy(deep=True)\n",
    "    fail_df.drop(columns='label', inplace=True)\n",
    "    x_train_success, x_test_success,y_train_success, y_test_success = train_test_split(success_df, success_df_label, test_size=test_size, shuffle=True, random_state=42)\n",
    "    x_train_fail, x_test_fail, y_train_fail, y_test_fail = train_test_split(fail_df, fail_df_label, test_size=test_size, shuffle = True, random_state=42)\n",
    "    x_train = pd.concat([x_train_success, x_train_fail], ignore_index=True)\n",
    "    x_test = pd.concat([x_test_success, x_test_fail], ignore_index=True)\n",
    "    y_train = pd.concat([y_train_success, y_train_fail], ignore_index=True)\n",
    "    y_test = pd.concat([y_test_success, y_test_fail], ignore_index=True)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_for_data_autoencoder(path: str, test_size: float, semisupervised: bool):\n",
    "    #Loading in the data\n",
    "    data_df = pd.read_csv(path)\n",
    "    #Converting the labels to binary numbers, 0 for success, 1 for failure\n",
    "    mask = data_df['Final Label'] == 'Success'\n",
    "    data_df.loc[mask, 'label'] = 0\n",
    "    data_df.loc[~mask, 'label'] = 1\n",
    "    #I do not need the index column\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "\n",
    "    #Once converted, the strings of the event IDs are also unnecessary\n",
    "    data_df['Events']  = data_df['New Event ID'].apply(ast.literal_eval)\n",
    "    #Calculating the maximum value of the En type events\n",
    "    max_n = max(int(e[1:]) for sublist in data_df['Events'] for e in sublist)\n",
    "    data_df['Event_Count_Vector'] = data_df['Events'].apply(lambda x: count_vector(x, max_n))\n",
    "    data_df.drop(columns=['Final Label', 'Unnamed: 0', 'New Event ID', 'Events', 'BlockId'], inplace=True)\n",
    "    count_vector_df = pd.DataFrame(data_df['Event_Count_Vector'].tolist(), index=data_df.index)\n",
    "\n",
    "    #For logistic regression\n",
    "    count_vector_df.columns = [f'feature_{i+1}' for i in range(count_vector_df.shape[1])]\n",
    "    data_df = pd.concat([data_df, count_vector_df], axis=1)\n",
    "    data_df.drop(columns='Event_Count_Vector', inplace = True)\n",
    "\n",
    "\n",
    "    success_df = data_df.loc[data_df['label'] == 0].copy(deep=True)\n",
    "    fail_df = data_df.loc[data_df['label'] == 1].copy(deep=True)\n",
    "    success_df_label = success_df['label'].copy(deep=True)\n",
    "    success_df.drop(columns='label', inplace=True)\n",
    "    fail_df_label = fail_df['label'].copy(deep=True)\n",
    "    fail_df.drop(columns='label', inplace=True)\n",
    "    x_train_success, x_test_success,y_train_success, y_test_success = train_test_split(success_df, success_df_label, test_size=test_size, shuffle=True, random_state=42)\n",
    "    x_train_fail, x_test_fail, y_train_fail, y_test_fail = train_test_split(fail_df, fail_df_label, test_size=test_size, shuffle = True, random_state=42)\n",
    "    x_train = pd.concat([x_train_success, x_train_fail], ignore_index=True)\n",
    "    x_test = pd.concat([x_test_success, x_test_fail], ignore_index=True)\n",
    "    y_train = pd.concat([y_train_success, y_train_fail], ignore_index=True)\n",
    "    y_test = pd.concat([y_test_success, y_test_fail], ignore_index=True)\n",
    "    if semisupervised:\n",
    "        return x_train_success, y_train_success, x_test_success, y_test_success, x_train_fail, y_train_fail, x_test_fail, y_test_fail\n",
    "    else:\n",
    "        return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diplomamunka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
